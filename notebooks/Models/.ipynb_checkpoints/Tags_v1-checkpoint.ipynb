{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "span.sub-q {\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "div.gc { \n",
       "\tbackground-color: #AEDE94;\n",
       "\tborder-color: #E9967A; \t \n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 12pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Increase notebook to take the full width of the screen\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of songs missing \"song hotness\": 43.5%\n",
      "(10000, 54)\n"
     ]
    }
   ],
   "source": [
    "# Load the selected dataset, and check for missing 'song hotness'\n",
    "\n",
    "subset_full = pd.read_csv('subset_full.csv')\n",
    "subset_full = subset_full.drop(columns=['Unnamed: 0'])\n",
    "missing = subset_full['song_hotttnesss'].isna().sum() / len(subset_full)*100\n",
    "print('Number of songs missing \"song hotness\": {}%'.format(np.around(missing, 1)))\n",
    "print(subset_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of songs missing \"song hotness\": 0.0%\n",
      "(5648, 54)\n"
     ]
    }
   ],
   "source": [
    "# Select only the data with song_hotness, and confirm\n",
    "\n",
    "subset_full = subset_full.dropna(subset = ['song_hotttnesss'])\n",
    "missing = subset_full['song_hotttnesss'].isna().sum() / len(subset_full)*100\n",
    "print('Number of songs missing \"song hotness\": {}%'.format(np.around(missing, 1)))\n",
    "print(subset_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5648, 54)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only the data artist terms, as this is what will be used in this notebook\n",
    "\n",
    "subset_full = subset_full.dropna(subset = ['artist_terms'])\n",
    "subset_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the columns that are not related to this. Most are covered in other notebooks\n",
    "\n",
    "tagrelated_columns = ['song_hotttnesss','track_id', 'artist_terms', 'artist_terms_freq', 'artist_terms_weight']\n",
    "data = subset_full[tagrelated_columns]\n",
    "data = data.reset_index().drop(columns=['index'])\n",
    "\n",
    "# Start process of splitting up terms\n",
    "data['artist_terms'] = data['artist_terms'].str.split('\\'')\n",
    "data['artist_terms'] = data['artist_terms'].str[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_hotttnesss</th>\n",
       "      <th>track_id</th>\n",
       "      <th>artist_terms</th>\n",
       "      <th>artist_terms_freq</th>\n",
       "      <th>artist_terms_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.602120</td>\n",
       "      <td>TRAAAAW128F429D538</td>\n",
       "      <td>[hip hop,  , underground rap,  , g funk,  , al...</td>\n",
       "      <td>[1.         0.77613623 0.72966979 0.68301072 0...</td>\n",
       "      <td>[1.         0.89793596 0.88426185 0.84262975 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.604501</td>\n",
       "      <td>TRAAAFD128F92F423A</td>\n",
       "      <td>[pop punk,  , ska punk,  , breakcore,  , alter...</td>\n",
       "      <td>[0.8872883  0.79020373 0.79020373 0.79020373 0...</td>\n",
       "      <td>[1.         0.96090574 0.95923662 0.94674975 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.265861</td>\n",
       "      <td>TRAAARJ128F9320760</td>\n",
       "      <td>[new wave,  , progressive rock,  , space rock,...</td>\n",
       "      <td>[0.95976625 0.97039005 0.82199342 0.82199342 0...</td>\n",
       "      <td>[1.         0.98696192 0.98306453 0.96580916 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>TRAAAVO128F93133D4</td>\n",
       "      <td>[alternative rock,  , indie rock,  , rock,  , ...</td>\n",
       "      <td>[0.95608075 0.92130641 1.         0.68760239 0...</td>\n",
       "      <td>[1.         0.95787086 0.95089056 0.93066094 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.265861</td>\n",
       "      <td>TRAABCL128F4286650</td>\n",
       "      <td>[ccm,  , religious music,  , los angeles,  , c...</td>\n",
       "      <td>[1.         0.87337884 0.82439509 0.82439509 0...</td>\n",
       "      <td>[1.         0.90446866 0.86751209 0.84218695 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   song_hotttnesss            track_id  \\\n",
       "0         0.602120  TRAAAAW128F429D538   \n",
       "1         0.604501  TRAAAFD128F92F423A   \n",
       "2         0.265861  TRAAARJ128F9320760   \n",
       "3         0.000000  TRAAAVO128F93133D4   \n",
       "4         0.265861  TRAABCL128F4286650   \n",
       "\n",
       "                                        artist_terms  \\\n",
       "0  [hip hop,  , underground rap,  , g funk,  , al...   \n",
       "1  [pop punk,  , ska punk,  , breakcore,  , alter...   \n",
       "2  [new wave,  , progressive rock,  , space rock,...   \n",
       "3  [alternative rock,  , indie rock,  , rock,  , ...   \n",
       "4  [ccm,  , religious music,  , los angeles,  , c...   \n",
       "\n",
       "                                   artist_terms_freq  \\\n",
       "0  [1.         0.77613623 0.72966979 0.68301072 0...   \n",
       "1  [0.8872883  0.79020373 0.79020373 0.79020373 0...   \n",
       "2  [0.95976625 0.97039005 0.82199342 0.82199342 0...   \n",
       "3  [0.95608075 0.92130641 1.         0.68760239 0...   \n",
       "4  [1.         0.87337884 0.82439509 0.82439509 0...   \n",
       "\n",
       "                                 artist_terms_weight  \n",
       "0  [1.         0.89793596 0.88426185 0.84262975 0...  \n",
       "1  [1.         0.96090574 0.95923662 0.94674975 0...  \n",
       "2  [1.         0.98696192 0.98306453 0.96580916 0...  \n",
       "3  [1.         0.95787086 0.95089056 0.93066094 0...  \n",
       "4  [1.         0.90446866 0.86751209 0.84218695 0...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm data\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the artist terms into separate keywords, as well as create list of all possible keywords\n",
    "\n",
    "data['terms_count'] = 0\n",
    "data = data.astype('object')\n",
    "all_terms = []\n",
    "\n",
    "for i,x in enumerate(data.iterrows()):\n",
    "    data['artist_terms'].astype(object)\n",
    "    temp = []\n",
    "    for y in x[1][2]:\n",
    "        if re.search('[a-zA-Z]', y):\n",
    "            temp.append(y)\n",
    "    data.loc[i,'artist_terms'] = temp\n",
    "    data.loc[i,'terms_count'] = len(temp)\n",
    "    all_terms.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each song has a separate list within a list of its terms\n",
    "# Create one large list of all possible terms \n",
    "\n",
    "flat_all_terms = reduce(operator.concat, all_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 3100 different artist terms used in the dataset\n"
     ]
    }
   ],
   "source": [
    "# Create a counter of how many times each term is used\n",
    "\n",
    "count_all_terms = Counter(flat_all_terms)\n",
    "print(\"There are a total of {} different artist terms used in the dataset\".format(len(count_all_terms)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the appropriate number of terms to test for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a total of 3100 artist terms in use. Some terms are used very rarely, and hence do most likely not add value to our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first look at the distribution of the terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "keys = count_all_terms.keys()\n",
    "y_pos = np.arange(len(keys))\n",
    "x_pos = count_all_terms.values()\n",
    "\n",
    "plt.bar(y_pos, x_pos, align='center', alpha=0.4)\n",
    "plt.xlabel('Tags')\n",
    "plt.ylabel('Songs tagged by this label')\n",
    "plt.title('Distribution of tag count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of tags that are used for many songs, while there is a large tail of terms not used very often. \n",
    "\n",
    "Let us limit the terms to the ones used for more than 20 songs, and we will see the distribution looks better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-174-37671e41cd7b>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-174-37671e41cd7b>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    print(\"There is now {} artist terms\".format(len(count_all_terms))\u001b[0m\n\u001b[0m                                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "min_threshold = 20\n",
    "\n",
    "for key, cnts in list(count_all_terms.items()):   # list is important here\n",
    "    if cnts < min_threshold:\n",
    "        del count_all_terms[key]\n",
    "        \n",
    "print(\"There is now {} artist terms\".format(len(count_all_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "keys = count_all_terms.keys()\n",
    "y_pos = np.arange(len(keys))\n",
    "x_pos = count_all_terms.values()\n",
    "\n",
    "plt.bar(y_pos, x_pos, align='center', alpha=0.4)\n",
    "plt.xlabel('Tags')\n",
    "plt.ylabel('Songs tagged by this label')\n",
    "plt.title('Distribution of tag count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming\n",
    "\n",
    "To ensure that the artist terms are as common as possible among the different songs, do we implement stemming. \n",
    "\n",
    "Let's build a dictionary of all the artist terms used in more than 20 songs, in stemmed form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "temp = []\n",
    "stem_dict = {}\n",
    "for w in count_all_terms.keys():\n",
    "    s = ps.stem(w)\n",
    "    temp.append(s)\n",
    "    stem_dict[w] = s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to put the stemmed forms back into the dataset we are working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.astype('object')\n",
    "\n",
    "for i,x in enumerate(data.iterrows()):\n",
    "    temp = []\n",
    "    for y in x[1][2]:\n",
    "        if y in stem_dict.keys():\n",
    "            temp.append(stem_dict[y])\n",
    "\n",
    "    data.loc[i,'artist_terms'] = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we need to make a one hot encoded version of the dataframe, that is more suitable for the models we want to run: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.copy()\n",
    "df = pd.DataFrame()\n",
    "mlb = MultiLabelBinarizer()\n",
    "data3 = data.join(pd.DataFrame(mlb.fit_transform(data2.pop('artist_terms')),\n",
    "                          columns=mlb.classes_,\n",
    "                          index=data2.index))\n",
    "data3 = data3.drop(columns=['\\n \"rock ',' \"rock '])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data into target and predictor sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/share/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/share/anaconda3/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "y = data3['song_hotttnesss']\n",
    "\n",
    "x = data3.drop(columns=['song_hotttnesss','track_id', 'artist_terms_freq', 'artist_terms_weight', 'artist_terms'])\n",
    "\n",
    "x = StandardScaler().fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify by only setting top 25% of song_hotness to be \"hot\" and the rest \"not\"\n",
    "\n",
    "def convert_y_to_categorical(cutoff = 0.75):\n",
    "    threshold = y.quantile(cutoff)\n",
    "    Y = [0 if i < threshold else 1 for i in y]\n",
    "    return np.array(Y)\n",
    "y = convert_y_to_categorical()\n",
    "y = y.astype('int')\n",
    "\n",
    "print(\"{f} % of the songs are classified as hot, while the rest is not\".format(y.mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test sets\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.1, random_state = 42)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, let's run a number of standard algoritms and see what we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test score for the Nearest Neighbors is 0.789381\n",
      "The test score for the Linear SVM is 0.775221\n",
      "The test score for the RBF SVM is 0.803540\n",
      "The test score for the Gaussian Process is 0.800000\n",
      "The test score for the Decision Tree is 0.789381\n",
      "The test score for the Random Forest is 0.757522\n",
      "The test score for the Neural Net is 0.785841\n",
      "The test score for the AdaBoost is 0.784071\n",
      "The test score for the Naive Bayes is 0.527434\n",
      "The test score for the QDA is 0.745133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/share/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "    # iterate over classifiers\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        clf.fit(x_train, y_train)\n",
    "        score = clf.score(x_test, y_test)\n",
    "        print(\"The test score for the {} is {:f}\".format(name, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us select two of the algoritms above, and run them with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate plot of the test and training learning curve.\n",
    "\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "# First model\n",
    "title = \"Learning Curves KNeighborsClassifier K=3\"\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "estimator = KNeighborsClassifier(3)\n",
    "plot_learning_curve(estimator, title, x_train, y_train, ylim=(0.7, 1.01), cv=cv, n_jobs=4)\n",
    "\n",
    "# Second model\n",
    "title = r\"Learning Curves (SVM, RBF kernel, $\\gamma=0.001$)\"\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "estimator = SVC(gamma=0.001)\n",
    "plot_learning_curve(estimator, title, x_train, y_train, (0.7, 1.01), cv=cv, n_jobs=4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us then try neural networks, and see if the results may improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a baseline model, to see what results we may get\n",
    "\n",
    "def create_baseline():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(817, input_dim=817, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3388/3388 [==============================] - 3s 907us/step - loss: 0.6851 - acc: 0.7583\n",
      "Epoch 2/5\n",
      "3388/3388 [==============================] - 2s 736us/step - loss: 0.3755 - acc: 0.8442\n",
      "Epoch 3/5\n",
      "3388/3388 [==============================] - 3s 812us/step - loss: 0.3483 - acc: 0.8536\n",
      "Epoch 4/5\n",
      "3388/3388 [==============================] - 3s 753us/step - loss: 0.3156 - acc: 0.8687\n",
      "Epoch 5/5\n",
      "3388/3388 [==============================] - 2s 736us/step - loss: 0.3186 - acc: 0.8719\n",
      "1695/1695 [==============================] - 1s 380us/step\n",
      "Epoch 1/5\n",
      "3389/3389 [==============================] - 3s 966us/step - loss: 0.6673 - acc: 0.7572\n",
      "Epoch 2/5\n",
      "3389/3389 [==============================] - 3s 760us/step - loss: 0.3709 - acc: 0.8472\n",
      "Epoch 3/5\n",
      "3389/3389 [==============================] - 3s 744us/step - loss: 0.3327 - acc: 0.8687\n",
      "Epoch 4/5\n",
      "3389/3389 [==============================] - 3s 741us/step - loss: 0.3190 - acc: 0.8743\n",
      "Epoch 5/5\n",
      "3389/3389 [==============================] - 3s 779us/step - loss: 0.3058 - acc: 0.8834\n",
      "1694/1694 [==============================] - 1s 422us/step\n",
      "Epoch 1/5\n",
      "3389/3389 [==============================] - 3s 933us/step - loss: 0.6917 - acc: 0.7577\n",
      "Epoch 2/5\n",
      "3389/3389 [==============================] - 3s 741us/step - loss: 0.3793 - acc: 0.8522\n",
      "Epoch 3/5\n",
      "3389/3389 [==============================] - 3s 785us/step - loss: 0.3268 - acc: 0.8696\n",
      "Epoch 4/5\n",
      "3389/3389 [==============================] - 3s 779us/step - loss: 0.3183 - acc: 0.8772\n",
      "Epoch 5/5\n",
      "3389/3389 [==============================] - 3s 739us/step - loss: 0.3158 - acc: 0.8823\n",
      "1694/1694 [==============================] - 1s 405us/step\n",
      "Results: 78.69% (0.25%)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=create_baseline, epochs=5, batch_size=5, verbose=1)\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, x_train, y_train, cv=kfold)\n",
    "print(\"A mean of %.2f%%  with a standard deviation of %.2f%%\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4065/4065 [==============================] - 6s 2ms/step - loss: 0.4690 - acc: 0.7934\n",
      "Epoch 2/5\n",
      "4065/4065 [==============================] - 4s 965us/step - loss: 0.3545 - acc: 0.8399\n",
      "Epoch 3/5\n",
      "4065/4065 [==============================] - 4s 930us/step - loss: 0.3016 - acc: 0.8659\n",
      "Epoch 4/5\n",
      "4065/4065 [==============================] - 4s 1ms/step - loss: 0.2537 - acc: 0.8792\n",
      "Epoch 5/5\n",
      "4065/4065 [==============================] - 4s 931us/step - loss: 0.2339 - acc: 0.8834\n",
      "1018/1018 [==============================] - 1s 1ms/step\n",
      "Epoch 1/5\n",
      "4066/4066 [==============================] - 7s 2ms/step - loss: 0.4722 - acc: 0.7863\n",
      "Epoch 2/5\n",
      "4066/4066 [==============================] - 4s 935us/step - loss: 0.3566 - acc: 0.8433\n",
      "Epoch 3/5\n",
      "4066/4066 [==============================] - 4s 1ms/step - loss: 0.2954 - acc: 0.8556\n",
      "Epoch 4/5\n",
      "4066/4066 [==============================] - 4s 935us/step - loss: 0.2494 - acc: 0.8743\n",
      "Epoch 5/5\n",
      "4066/4066 [==============================] - 4s 968us/step - loss: 0.2484 - acc: 0.8770\n",
      "1017/1017 [==============================] - 2s 2ms/step\n",
      "Epoch 1/5\n",
      "4067/4067 [==============================] - 7s 2ms/step - loss: 0.4633 - acc: 0.7976\n",
      "Epoch 2/5\n",
      "4067/4067 [==============================] - 4s 1ms/step - loss: 0.3527 - acc: 0.8495\n",
      "Epoch 3/5\n",
      "4067/4067 [==============================] - 4s 939us/step - loss: 0.2930 - acc: 0.8660\n",
      "Epoch 4/5\n",
      "4067/4067 [==============================] - 4s 981us/step - loss: 0.2454 - acc: 0.8812\n",
      "Epoch 5/5\n",
      "4067/4067 [==============================] - 4s 962us/step - loss: 0.2242 - acc: 0.8879\n",
      "1016/1016 [==============================] - 2s 2ms/step\n",
      "Epoch 1/5\n",
      "4067/4067 [==============================] - 7s 2ms/step - loss: 0.4706 - acc: 0.7819\n",
      "Epoch 2/5\n",
      "4067/4067 [==============================] - 4s 937us/step - loss: 0.3593 - acc: 0.8402\n",
      "Epoch 3/5\n",
      "4067/4067 [==============================] - 4s 996us/step - loss: 0.3050 - acc: 0.8603\n",
      "Epoch 4/5\n",
      "4067/4067 [==============================] - 4s 950us/step - loss: 0.2587 - acc: 0.8790\n",
      "Epoch 5/5\n",
      "4067/4067 [==============================] - 4s 953us/step - loss: 0.2312 - acc: 0.8881\n",
      "1016/1016 [==============================] - 2s 2ms/step\n",
      "Epoch 1/5\n",
      "4067/4067 [==============================] - 7s 2ms/step - loss: 0.4728 - acc: 0.7898\n",
      "Epoch 2/5\n",
      "4067/4067 [==============================] - 4s 987us/step - loss: 0.3578 - acc: 0.8389\n",
      "Epoch 3/5\n",
      "4067/4067 [==============================] - 4s 940us/step - loss: 0.2972 - acc: 0.8645\n",
      "Epoch 4/5\n",
      "4067/4067 [==============================] - 4s 970us/step - loss: 0.2582 - acc: 0.8790\n",
      "Epoch 5/5\n",
      "4067/4067 [==============================] - 4s 965us/step - loss: 0.2205 - acc: 0.8849\n",
      "1016/1016 [==============================] - 2s 2ms/step\n",
      "Larger: 80.86% (0.67%)\n"
     ]
    }
   ],
   "source": [
    "# Create a larger model, to see if the results may be improved\n",
    "def create_larger():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(817, input_dim=817, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(30, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_larger, epochs=5, batch_size=5, verbose=1)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, x_train, y_train, cv=kfold)\n",
    "print(\"A mean of %.2f%% with a standard deviation of %.2f%%\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.84716069e-02, 1.69379378e-02, 1.40786195e-02, 1.25247096e-02,\n",
       "       1.14755055e-02, 1.09660247e-02, 1.02795156e-02, 9.79184911e-03,\n",
       "       9.32172346e-03, 8.73483903e-03, 8.64407461e-03, 8.11433684e-03,\n",
       "       7.93920779e-03, 7.31021595e-03, 6.73987394e-03, 6.47597308e-03,\n",
       "       6.35716144e-03, 6.03926868e-03, 5.90004375e-03, 5.63005024e-03,\n",
       "       5.53725476e-03, 5.37664193e-03, 5.25525215e-03, 5.11773403e-03,\n",
       "       4.99395700e-03, 4.80611703e-03, 4.65717311e-03, 4.58715515e-03,\n",
       "       4.50668433e-03, 4.47027163e-03, 4.35667994e-03, 4.28022655e-03,\n",
       "       4.22711016e-03, 4.13766739e-03, 4.11218718e-03, 4.07629848e-03,\n",
       "       4.04605809e-03, 4.02367365e-03, 3.90787868e-03, 3.83413190e-03,\n",
       "       3.76987085e-03, 3.69299147e-03, 3.66211595e-03, 3.62328013e-03,\n",
       "       3.55356701e-03, 3.52369251e-03, 3.46178468e-03, 3.42783351e-03,\n",
       "       3.39920096e-03, 3.36663555e-03, 3.32711477e-03, 3.31326796e-03,\n",
       "       3.29467194e-03, 3.25125342e-03, 3.21680849e-03, 3.18997719e-03,\n",
       "       3.16322153e-03, 3.11595723e-03, 3.08607377e-03, 3.06107919e-03,\n",
       "       3.03863214e-03, 3.02658762e-03, 2.97860418e-03, 2.96343251e-03,\n",
       "       2.92358292e-03, 2.90163002e-03, 2.87734012e-03, 2.84743741e-03,\n",
       "       2.79989628e-03, 2.78397990e-03, 2.78006652e-03, 2.75564301e-03,\n",
       "       2.73765932e-03, 2.71568866e-03, 2.69213169e-03, 2.68147672e-03,\n",
       "       2.65388418e-03, 2.64273253e-03, 2.63243484e-03, 2.60464542e-03,\n",
       "       2.58318715e-03, 2.55723655e-03, 2.54020389e-03, 2.53214591e-03,\n",
       "       2.52371982e-03, 2.51398423e-03, 2.48531157e-03, 2.45749588e-03,\n",
       "       2.44467583e-03, 2.43710957e-03, 2.41778925e-03, 2.40386761e-03,\n",
       "       2.39237725e-03, 2.37927205e-03, 2.37294491e-03, 2.35816039e-03,\n",
       "       2.33957532e-03, 2.32746391e-03, 2.31252140e-03, 2.30960399e-03,\n",
       "       2.29041429e-03, 2.27416990e-03, 2.26742683e-03, 2.24695607e-03,\n",
       "       2.23473665e-03, 2.21353688e-03, 2.21150641e-03, 2.19090031e-03,\n",
       "       2.17902350e-03, 2.16976728e-03, 2.16135658e-03, 2.14967664e-03,\n",
       "       2.14524866e-03, 2.13505993e-03, 2.12931716e-03, 2.11590645e-03,\n",
       "       2.11045093e-03, 2.09011539e-03, 2.08474873e-03, 2.06398073e-03,\n",
       "       2.05881854e-03, 2.04567674e-03, 2.03832155e-03, 2.03679885e-03,\n",
       "       2.03198526e-03, 2.01208545e-03, 2.00281749e-03, 1.99756448e-03,\n",
       "       1.98300255e-03, 1.97222760e-03, 1.97069574e-03, 1.95740080e-03,\n",
       "       1.94645469e-03, 1.94056494e-03, 1.93350320e-03, 1.92888905e-03,\n",
       "       1.92328281e-03, 1.91534594e-03, 1.89421886e-03, 1.88369044e-03,\n",
       "       1.87466415e-03, 1.86525367e-03, 1.85727730e-03, 1.85280598e-03,\n",
       "       1.84835102e-03, 1.83887201e-03, 1.83302761e-03, 1.82411498e-03,\n",
       "       1.81467821e-03, 1.80025120e-03, 1.80023276e-03, 1.79852361e-03,\n",
       "       1.78509414e-03, 1.78089253e-03, 1.77483567e-03, 1.76479402e-03,\n",
       "       1.75982948e-03, 1.75627044e-03, 1.73625423e-03, 1.73328025e-03,\n",
       "       1.72766735e-03, 1.72228687e-03, 1.71932538e-03, 1.71300872e-03,\n",
       "       1.70525752e-03, 1.69700762e-03, 1.69069830e-03, 1.68346656e-03,\n",
       "       1.67938381e-03, 1.66838924e-03, 1.66324832e-03, 1.65636101e-03,\n",
       "       1.64435249e-03, 1.63786452e-03, 1.63065418e-03, 1.62500745e-03,\n",
       "       1.61626502e-03, 1.61368909e-03, 1.60770154e-03, 1.60080157e-03,\n",
       "       1.59269585e-03, 1.58961001e-03, 1.57323698e-03, 1.57155497e-03,\n",
       "       1.56677910e-03, 1.56217809e-03, 1.55354003e-03, 1.54545845e-03,\n",
       "       1.54169505e-03, 1.53800905e-03, 1.53215401e-03, 1.52601997e-03,\n",
       "       1.52050830e-03, 1.51492288e-03, 1.50986419e-03, 1.50089998e-03,\n",
       "       1.49538631e-03, 1.48470819e-03, 1.48441692e-03, 1.47843226e-03,\n",
       "       1.47369566e-03, 1.46385400e-03, 1.46134561e-03, 1.44896294e-03,\n",
       "       1.44717859e-03, 1.44368077e-03, 1.43742741e-03, 1.43175727e-03,\n",
       "       1.42826911e-03, 1.42059072e-03, 1.41649053e-03, 1.41316026e-03,\n",
       "       1.41089492e-03, 1.40362810e-03, 1.39806768e-03, 1.38488899e-03,\n",
       "       1.38448667e-03, 1.37661168e-03, 1.36777222e-03, 1.36712032e-03,\n",
       "       1.36286020e-03, 1.35643008e-03, 1.35489097e-03, 1.35147799e-03,\n",
       "       1.34411858e-03, 1.34066527e-03, 1.33632801e-03, 1.33168575e-03,\n",
       "       1.32646601e-03, 1.32022966e-03, 1.31272822e-03, 1.30884655e-03,\n",
       "       1.30187602e-03, 1.30050125e-03, 1.29514796e-03, 1.29079172e-03,\n",
       "       1.28394191e-03, 1.27937332e-03, 1.27643798e-03, 1.27256048e-03,\n",
       "       1.26481843e-03, 1.26140836e-03, 1.25731504e-03, 1.25418564e-03,\n",
       "       1.25199589e-03, 1.24746536e-03, 1.24004820e-03, 1.23613774e-03,\n",
       "       1.23456304e-03, 1.23175482e-03, 1.22874767e-03, 1.22625866e-03,\n",
       "       1.22339024e-03, 1.21562730e-03, 1.20980679e-03, 1.20840598e-03,\n",
       "       1.20428686e-03, 1.19712909e-03, 1.19530368e-03, 1.18909560e-03,\n",
       "       1.18373743e-03, 1.18201189e-03, 1.17611263e-03, 1.17050946e-03,\n",
       "       1.16482731e-03, 1.15829466e-03, 1.15762854e-03, 1.15410546e-03,\n",
       "       1.15151315e-03, 1.14266617e-03, 1.13847520e-03, 1.13823816e-03,\n",
       "       1.13435550e-03, 1.12979962e-03, 1.12750720e-03, 1.12322087e-03,\n",
       "       1.11885383e-03, 1.11636500e-03, 1.11245716e-03, 1.10644796e-03,\n",
       "       1.10350175e-03, 1.09410627e-03, 1.09101600e-03, 1.08666778e-03,\n",
       "       1.08532545e-03, 1.07685841e-03, 1.07564232e-03, 1.07326051e-03,\n",
       "       1.07021483e-03, 1.06836614e-03, 1.06335152e-03, 1.05707089e-03,\n",
       "       1.05229744e-03, 1.05122043e-03, 1.04860373e-03, 1.04330679e-03,\n",
       "       1.03920936e-03, 1.03609311e-03, 1.03574539e-03, 1.03029346e-03,\n",
       "       1.02862111e-03, 1.02482298e-03, 1.02399727e-03, 1.01916652e-03,\n",
       "       1.01559924e-03, 1.00878422e-03, 1.00642031e-03, 1.00404429e-03,\n",
       "       9.98429980e-04, 9.95889302e-04, 9.91556222e-04, 9.90221789e-04,\n",
       "       9.88771245e-04, 9.83647826e-04, 9.79655844e-04, 9.77478331e-04,\n",
       "       9.75107028e-04, 9.74035023e-04, 9.65848043e-04, 9.63715366e-04,\n",
       "       9.59422415e-04, 9.56387062e-04, 9.54815172e-04, 9.53160322e-04,\n",
       "       9.47994179e-04, 9.45284033e-04, 9.43072489e-04, 9.41432710e-04,\n",
       "       9.34628032e-04, 9.32432227e-04, 9.29960088e-04, 9.29173423e-04,\n",
       "       9.23487465e-04, 9.18222802e-04, 9.12481238e-04, 9.10288578e-04,\n",
       "       9.09539904e-04, 9.02539763e-04, 8.97939747e-04, 8.96493122e-04,\n",
       "       8.94049938e-04, 8.92703439e-04, 8.89860303e-04, 8.86677839e-04,\n",
       "       8.84322786e-04, 8.83378464e-04, 8.76277453e-04, 8.72960630e-04,\n",
       "       8.69254181e-04, 8.67226853e-04, 8.64336897e-04, 8.60110262e-04,\n",
       "       8.58302412e-04, 8.51332912e-04, 8.49198326e-04, 8.47618330e-04,\n",
       "       8.44585128e-04, 8.42158185e-04, 8.40510193e-04, 8.37754523e-04,\n",
       "       8.35318806e-04, 8.33757936e-04, 8.28000265e-04, 8.26114221e-04,\n",
       "       8.22554770e-04, 8.18035532e-04, 8.16332366e-04, 8.15920932e-04,\n",
       "       8.13370868e-04, 8.10406745e-04, 8.09996058e-04, 8.04229490e-04,\n",
       "       8.01449390e-04, 8.00121060e-04, 7.94434168e-04, 7.93419074e-04,\n",
       "       7.90204422e-04, 7.89487532e-04, 7.84784733e-04, 7.83218547e-04,\n",
       "       7.80509024e-04, 7.75793677e-04, 7.73180546e-04, 7.71735305e-04,\n",
       "       7.68086248e-04, 7.67542189e-04, 7.65845494e-04, 7.62922561e-04,\n",
       "       7.57866060e-04, 7.54959837e-04, 7.53544867e-04, 7.52447692e-04,\n",
       "       7.49772352e-04, 7.47762854e-04, 7.46774184e-04, 7.43619997e-04,\n",
       "       7.41842937e-04, 7.36302556e-04, 7.31708108e-04, 7.29430369e-04,\n",
       "       7.27235891e-04, 7.24223328e-04, 7.22422976e-04, 7.20414678e-04,\n",
       "       7.18483767e-04, 7.14130308e-04, 7.10225459e-04, 7.09033976e-04,\n",
       "       7.07462537e-04, 7.02925008e-04, 7.01798459e-04, 7.00083676e-04,\n",
       "       6.96224188e-04, 6.94897898e-04, 6.92435797e-04, 6.91498952e-04,\n",
       "       6.90012366e-04, 6.88283105e-04, 6.84648929e-04, 6.83532564e-04,\n",
       "       6.82123197e-04, 6.79649365e-04, 6.77048023e-04, 6.72773191e-04,\n",
       "       6.69714019e-04, 6.66823574e-04, 6.65130766e-04, 6.63161612e-04,\n",
       "       6.59811687e-04, 6.56756110e-04, 6.56715899e-04, 6.55398418e-04,\n",
       "       6.54892350e-04, 6.50789776e-04, 6.47773230e-04, 6.44093214e-04,\n",
       "       6.41724905e-04, 6.40560894e-04, 6.38441387e-04, 6.34558898e-04,\n",
       "       6.31675007e-04, 6.30441428e-04, 6.26749337e-04, 6.25665074e-04,\n",
       "       6.24042883e-04, 6.21020328e-04, 6.20546828e-04, 6.17574720e-04,\n",
       "       6.17075644e-04, 6.15910852e-04, 6.09732985e-04, 6.07937599e-04,\n",
       "       6.07183595e-04, 6.04955963e-04, 6.03916833e-04, 6.00111186e-04,\n",
       "       5.99049947e-04, 5.97202059e-04, 5.95795016e-04, 5.92456414e-04,\n",
       "       5.90467733e-04, 5.88891437e-04, 5.86815361e-04, 5.84364182e-04,\n",
       "       5.81494388e-04, 5.79238307e-04, 5.76213089e-04, 5.75675667e-04,\n",
       "       5.74785888e-04, 5.71039525e-04, 5.70791894e-04, 5.70211616e-04,\n",
       "       5.65787852e-04, 5.65421573e-04, 5.63667365e-04, 5.60774408e-04,\n",
       "       5.57229858e-04, 5.57099515e-04, 5.55775213e-04, 5.53073235e-04,\n",
       "       5.50515992e-04, 5.48670560e-04, 5.45524908e-04, 5.44332787e-04,\n",
       "       5.42467100e-04, 5.41374113e-04, 5.39480157e-04, 5.35558382e-04,\n",
       "       5.33607337e-04, 5.32854708e-04, 5.30754249e-04, 5.29956930e-04,\n",
       "       5.26882286e-04, 5.25485480e-04, 5.23861317e-04, 5.21401627e-04,\n",
       "       5.19680103e-04, 5.17780830e-04, 5.15440899e-04, 5.14285057e-04,\n",
       "       5.13203411e-04, 5.10367105e-04, 5.07560841e-04, 5.06491745e-04,\n",
       "       5.05406939e-04, 5.03981579e-04, 5.02279625e-04, 5.00365244e-04,\n",
       "       4.99636116e-04, 4.98512742e-04, 4.94818618e-04, 4.93041957e-04,\n",
       "       4.92053527e-04, 4.89062791e-04, 4.87459314e-04, 4.84916279e-04,\n",
       "       4.82784545e-04, 4.81590157e-04, 4.80461616e-04, 4.79608106e-04,\n",
       "       4.77467045e-04, 4.75754844e-04, 4.72047779e-04, 4.70010529e-04,\n",
       "       4.67684436e-04, 4.66842714e-04, 4.66533182e-04, 4.62316790e-04,\n",
       "       4.61860718e-04, 4.60439883e-04, 4.59750213e-04, 4.55697963e-04,\n",
       "       4.54185489e-04, 4.53649154e-04, 4.52002309e-04, 4.49745392e-04,\n",
       "       4.49131438e-04, 4.47194835e-04, 4.45243934e-04, 4.44968711e-04,\n",
       "       4.43747105e-04, 4.42502826e-04, 4.39578814e-04, 4.38934626e-04,\n",
       "       4.36754181e-04, 4.35029737e-04, 4.33535935e-04, 4.30950110e-04,\n",
       "       4.30113568e-04, 4.27346323e-04, 4.26304716e-04, 4.23654207e-04,\n",
       "       4.23163513e-04, 4.19329434e-04, 4.18845191e-04, 4.16769471e-04,\n",
       "       4.15460723e-04, 4.13859371e-04, 4.12542153e-04, 4.11888974e-04,\n",
       "       4.10745738e-04, 4.07981527e-04, 4.07283800e-04, 4.05212611e-04,\n",
       "       4.04548169e-04, 4.03749748e-04, 4.02234057e-04, 4.00477056e-04,\n",
       "       3.98977716e-04, 3.98753581e-04, 3.97000971e-04, 3.95273285e-04,\n",
       "       3.93772905e-04, 3.92903419e-04, 3.91424281e-04, 3.88551518e-04,\n",
       "       3.87617791e-04, 3.84676147e-04, 3.83970811e-04, 3.82477759e-04,\n",
       "       3.81671064e-04, 3.79589208e-04, 3.77404658e-04, 3.76793086e-04,\n",
       "       3.75138102e-04, 3.74972346e-04, 3.73338764e-04, 3.72605014e-04,\n",
       "       3.70218140e-04, 3.67810551e-04, 3.67724747e-04, 3.66461725e-04,\n",
       "       3.63461553e-04, 3.61903853e-04, 3.61042724e-04, 3.59478771e-04,\n",
       "       3.58334338e-04, 3.57398591e-04, 3.55680394e-04, 3.53108238e-04,\n",
       "       3.52815775e-04, 3.51739370e-04, 3.50671541e-04, 3.49956141e-04,\n",
       "       3.48203112e-04, 3.46070130e-04, 3.45332001e-04, 3.44754985e-04,\n",
       "       3.42165043e-04, 3.39941148e-04, 3.39822967e-04, 3.39380426e-04,\n",
       "       3.36606425e-04, 3.34704519e-04, 3.33817932e-04, 3.33406315e-04,\n",
       "       3.31869728e-04, 3.30409490e-04, 3.29370683e-04, 3.28393555e-04,\n",
       "       3.26413939e-04, 3.25220788e-04, 3.24504323e-04, 3.22675313e-04,\n",
       "       3.20688537e-04, 3.19612913e-04, 3.18303707e-04, 3.15265107e-04,\n",
       "       3.14778745e-04, 3.14578805e-04, 3.13425933e-04, 3.12194583e-04,\n",
       "       3.09091490e-04, 3.08106543e-04, 3.07644247e-04, 3.06522387e-04,\n",
       "       3.04437535e-04, 3.03778679e-04, 3.02320441e-04, 3.01798794e-04,\n",
       "       3.00531579e-04, 2.98629057e-04, 2.97328090e-04, 2.96923466e-04,\n",
       "       2.95975032e-04, 2.93582871e-04, 2.92792024e-04, 2.91456201e-04,\n",
       "       2.90442393e-04, 2.89828910e-04, 2.87928730e-04, 2.86734305e-04,\n",
       "       2.85913046e-04, 2.83841039e-04, 2.83147513e-04, 2.82290166e-04,\n",
       "       2.81831570e-04, 2.80302067e-04, 2.79280091e-04, 2.76694236e-04,\n",
       "       2.75994226e-04, 2.74805599e-04, 2.74134327e-04, 2.72111268e-04,\n",
       "       2.71279112e-04, 2.69747081e-04, 2.68012307e-04, 2.66495808e-04,\n",
       "       2.65906743e-04, 2.63979734e-04, 2.62417079e-04, 2.61244089e-04,\n",
       "       2.59839671e-04, 2.59099900e-04, 2.58537006e-04, 2.58044945e-04,\n",
       "       2.57470957e-04, 2.55976332e-04, 2.53552442e-04, 2.52375424e-04,\n",
       "       2.50721365e-04, 2.49650312e-04, 2.48497845e-04, 2.48423726e-04,\n",
       "       2.47113778e-04, 2.46149815e-04, 2.44929955e-04, 2.42884885e-04,\n",
       "       2.41878895e-04, 2.40707047e-04, 2.39770792e-04, 2.38793612e-04,\n",
       "       2.38024454e-04, 2.36971481e-04, 2.34732292e-04, 2.34322923e-04,\n",
       "       2.32560511e-04, 2.32000088e-04, 2.31567051e-04, 2.31432752e-04,\n",
       "       2.30437797e-04, 2.28233564e-04, 2.26330453e-04, 2.25232381e-04,\n",
       "       2.23699339e-04, 2.23178563e-04, 2.22086239e-04, 2.21215937e-04,\n",
       "       2.20122950e-04, 2.18912075e-04, 2.17107484e-04, 2.17073886e-04,\n",
       "       2.16786404e-04, 2.15038827e-04, 2.13419743e-04, 2.12700667e-04,\n",
       "       2.11726825e-04, 2.09162976e-04, 2.07803302e-04, 2.06080753e-04,\n",
       "       2.05704254e-04, 2.05410441e-04, 2.02925947e-04, 2.02688895e-04,\n",
       "       2.01293704e-04, 2.00589443e-04, 1.99567158e-04, 1.97749824e-04,\n",
       "       1.95984928e-04, 1.94779486e-04, 1.94267751e-04, 1.92962376e-04,\n",
       "       1.92517161e-04, 1.91520806e-04, 1.90616057e-04, 1.88942528e-04,\n",
       "       1.88419058e-04, 1.87461847e-04, 1.85727286e-04, 1.84573762e-04,\n",
       "       1.83219266e-04, 1.81985057e-04, 1.81733541e-04, 1.79568438e-04,\n",
       "       1.78722923e-04, 1.77220458e-04, 1.76787787e-04, 1.74285141e-04,\n",
       "       1.74105158e-04, 1.73272362e-04, 1.72183102e-04, 1.70542749e-04,\n",
       "       1.69499542e-04, 1.68467312e-04, 1.67445242e-04, 1.66419664e-04,\n",
       "       1.66031080e-04, 1.64638215e-04, 1.62097528e-04, 1.60698006e-04,\n",
       "       1.60343524e-04, 1.59696389e-04, 1.58492594e-04, 1.57182097e-04,\n",
       "       1.56711179e-04, 1.56320942e-04, 1.54399358e-04, 1.53292050e-04,\n",
       "       1.52673777e-04, 1.50082534e-04, 1.48586219e-04, 1.47794430e-04,\n",
       "       1.47109605e-04, 1.45760613e-04, 1.44240851e-04, 1.43418724e-04,\n",
       "       1.42313269e-04, 1.41960411e-04, 1.40867240e-04, 1.39978648e-04,\n",
       "       1.38469714e-04, 1.36452831e-04, 1.35836141e-04, 1.33725137e-04,\n",
       "       1.33047692e-04, 1.32333016e-04, 1.30910484e-04, 1.28650158e-04,\n",
       "       1.27992671e-04, 1.25960657e-04, 1.23695951e-04, 1.22815707e-04,\n",
       "       1.21143346e-04, 1.20560785e-04, 1.20147209e-04, 1.18657155e-04,\n",
       "       1.17084263e-04, 1.16270314e-04, 1.15612438e-04, 1.13034737e-04,\n",
       "       1.09934417e-04, 1.09289110e-04, 1.06462029e-04, 1.06353963e-04,\n",
       "       1.03135496e-04, 1.01598562e-04, 1.00937457e-04, 9.99145963e-05,\n",
       "       9.54510152e-05, 9.37201682e-05, 9.06008258e-05, 6.84247562e-05,\n",
       "       6.80484758e-05, 6.45696299e-05, 6.10681597e-05, 5.76013748e-05,\n",
       "       1.30551521e-05])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lastly, check PCA if any predictors are very dominating\n",
    "pca_all = PCA()\n",
    "pca_all.fit(x_train)\n",
    "pca_all.explained_variance_ratio_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
