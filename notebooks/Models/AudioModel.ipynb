{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "span.sub-q {\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "div.gc { \n",
       "\tbackground-color: #AEDE94;\n",
       "\tborder-color: #E9967A; \t \n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 12pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import datetime\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import tables\n",
    "import io\n",
    "import gzip\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras import backend as K,objectives\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import model_from_json\n",
    "from sklearn.metrics import classification_report, confusion_matrix, mean_squared_error, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the Million Song Dataset subset (uncompressed) - change to the location on your laptop\n",
    "# Cannot store this on github as it is too large\n",
    "msd_subset_path = '../../MSD_data/MillionSongSubset/'\n",
    "\n",
    "# Keep these - folders match the structure of the uncompressed file\n",
    "msd_subset_data_path = os.path.join(msd_subset_path, 'data')\n",
    "msd_subset_addf_path = os.path.join(msd_subset_path, 'AdditionalFiles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Use Rhythm Histogram and Statistical Spectrum Descriptor data from http://www.ifs.tuwien.ac.at/mir/audiofeatureextraction.html to attempt to predict hotness*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh_hotness_clean = pd.read_pickle(msd_subset_path+'rh_and_hotness_clean.pkl')\n",
    "ssd_hotness_clean = pd.read_pickle(msd_subset_path+'ssd_and_hotness_clean.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Check for duplicate tracks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (ssd_hotness_clean.groupby('song_id').count()['track_id'] > 1).sum() == 0 \n",
    "assert (rh_hotness_clean.groupby('song_id').count()['track_id'] > 1).sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outline taken from https://www.pyimagesearch.com/2019/01/28/keras-regression-and-cnns/\n",
    "\n",
    "def create_cnn(width, height, depth, filters=(16, 32, 64), regress=True):\n",
    "    # initialize the input shape and channel dimension, assuming\n",
    "    # TensorFlow/channels-last ordering\n",
    "    inputShape = (width, height, depth)\n",
    "    chanDim = -1\n",
    "    # define the model input\n",
    "    inputs = Input(shape=inputShape)\n",
    "    # loop over the number of filters\n",
    "    for (i, f) in enumerate(filters):\n",
    "    # if this is the first CONV layer then set the input appropriately\n",
    "        if i == 0:\n",
    "            x = inputs\n",
    "        x = Conv2D(f, (3, 3), padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    # flatten the volume, then FC => RELU => BN => DROPOUT\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(16)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization(axis=chanDim)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    # apply another FC layer, this one to match the number of nodes coming out of the MLP\n",
    "    x = Dense(4)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    # check to see if the regression node should be added\n",
    "    if regress:\n",
    "        x = Dense(1, activation=\"linear\")(x)\n",
    "    # construct the CNN\n",
    "    model = Model(inputs, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Combine features into single dataset for training*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = rh_hotness_clean.song_hotttnesss\n",
    "x_rh = rh_hotness_clean.drop(['track_id', 'song_id', 'song_hotttnesss'], axis = 1)\n",
    "x_ssd = ssd_hotness_clean.drop(['track_id', 'song_id', 'song_hotttnesss'], axis = 1)\n",
    "x = np.concatenate((x_rh, x_ssd), axis = 1)\n",
    "# df = ssd_hotness_clean # rh_hotness_clean\n",
    "# x = df.drop(['track_id', 'song_id', 'song_hotttnesss'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_rh = 12 # 21 15\n",
    "h_rh = 19 # 8  4\n",
    "csv_logger = CSVLogger('history.log', separator=',', append=False)\n",
    "\n",
    "x = MinMaxScaler().fit_transform(x)\n",
    "(trainX, testX, trainY, testY) = train_test_split(x, y.values, test_size=0.25, random_state=109)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.expand_dims(trainX.reshape(trainX.shape[0], w_rh, h_rh), axis = -1)\n",
    "testX = np.expand_dims(testX.reshape(testX.shape[0], w_rh, h_rh), axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 12, 19, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 12, 19, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 12, 19, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 12, 19, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 9, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 9, 32)          4640      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 6, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 6, 9, 32)          128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 4, 64)          18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 3, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 3, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 25,945\n",
      "Trainable params: 25,689\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "model = create_cnn(w_rh, h_rh, 1, regress=True)\n",
    "opt = Adam(lr=1e-3, decay=1e-3 / 200)\n",
    "model.compile(loss=\"mean_absolute_percentage_error\", optimizer=opt, metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4236 samples, validate on 1412 samples\n",
      "Epoch 1/100\n",
      "4236/4236 [==============================] - 7s 2ms/step - loss: 11122137.0086 - acc: 0.2455 - val_loss: 11161730934.9169 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 59524.7981 - acc: 0.2524 - val_loss: 48981814.7880 - val_acc: 0.2585\n",
      "Epoch 3/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 45537.0386 - acc: 0.2524 - val_loss: 10513515.1793 - val_acc: 0.2585\n",
      "Epoch 4/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 66747.1027 - acc: 0.2524 - val_loss: 10075946.5765 - val_acc: 0.2585\n",
      "Epoch 5/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 47350.7094 - acc: 0.2524 - val_loss: 10077985.6018 - val_acc: 0.2585\n",
      "Epoch 6/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 39390.6199 - acc: 0.2524 - val_loss: 9463629.2063 - val_acc: 0.2585\n",
      "Epoch 7/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 45978.2990 - acc: 0.2524 - val_loss: 6373689.2005 - val_acc: 0.2585\n",
      "Epoch 8/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 64409.8961 - acc: 0.2524 - val_loss: 6270130.0762 - val_acc: 0.2585\n",
      "Epoch 9/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 59284.1820 - acc: 0.2524 - val_loss: 6137798.0793 - val_acc: 0.2585\n",
      "Epoch 10/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 50906.6305 - acc: 0.2524 - val_loss: 6181874.0566 - val_acc: 0.2585\n",
      "Epoch 11/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 50640.9745 - acc: 0.2524 - val_loss: 6075060.5359 - val_acc: 0.2585\n",
      "Epoch 12/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 50883.5635 - acc: 0.2524 - val_loss: 6245627.0163 - val_acc: 0.2585\n",
      "Epoch 13/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 60918.8829 - acc: 0.2524 - val_loss: 6099923.8763 - val_acc: 0.2585\n",
      "Epoch 14/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 70637.9390 - acc: 0.2524 - val_loss: 6168405.8029 - val_acc: 0.2585\n",
      "Epoch 15/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 58015.0271 - acc: 0.2524 - val_loss: 6150582.8528 - val_acc: 0.2585\n",
      "Epoch 16/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 60802.8771 - acc: 0.2524 - val_loss: 6166558.0722 - val_acc: 0.2585\n",
      "Epoch 17/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 52843.0844 - acc: 0.2524 - val_loss: 6079790.4717 - val_acc: 0.2585\n",
      "Epoch 18/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 49295.6619 - acc: 0.2524 - val_loss: 6138762.2421 - val_acc: 0.2585\n",
      "Epoch 19/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 56688.9354 - acc: 0.2524 - val_loss: 6115898.0886 - val_acc: 0.2585\n",
      "Epoch 20/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 55752.5286 - acc: 0.2524 - val_loss: 6172750.6283 - val_acc: 0.2585\n",
      "Epoch 21/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 55431.9410 - acc: 0.2524 - val_loss: 6188720.6225 - val_acc: 0.2585\n",
      "Epoch 22/100\n",
      "4236/4236 [==============================] - 7s 2ms/step - loss: 51232.9311 - acc: 0.2524 - val_loss: 6182444.8214 - val_acc: 0.2585\n",
      "Epoch 23/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 57390.8080 - acc: 0.2524 - val_loss: 6157937.6538 - val_acc: 0.2585\n",
      "Epoch 24/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 52851.4085 - acc: 0.2524 - val_loss: 6037064.3286 - val_acc: 0.2585\n",
      "Epoch 25/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 59793.7023 - acc: 0.2524 - val_loss: 6186431.8904 - val_acc: 0.2585\n",
      "Epoch 26/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 76026.4392 - acc: 0.2524 - val_loss: 5969884.6950 - val_acc: 0.2585\n",
      "Epoch 27/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 55573.7650 - acc: 0.2524 - val_loss: 6156555.1979 - val_acc: 0.2585\n",
      "Epoch 28/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 60029.9058 - acc: 0.2524 - val_loss: 6256556.3297 - val_acc: 0.2585\n",
      "Epoch 29/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 56139.6433 - acc: 0.2524 - val_loss: 6002097.8052 - val_acc: 0.2585\n",
      "Epoch 30/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 60294.1400 - acc: 0.2524 - val_loss: 6142756.0179 - val_acc: 0.2585\n",
      "Epoch 31/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 54092.4888 - acc: 0.2524 - val_loss: 6205148.2611 - val_acc: 0.2585\n",
      "Epoch 32/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 61914.2753 - acc: 0.2524 - val_loss: 6124736.1103 - val_acc: 0.2585\n",
      "Epoch 33/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 49579.3688 - acc: 0.2524 - val_loss: 6244920.7982 - val_acc: 0.2585\n",
      "Epoch 34/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 51209.3092 - acc: 0.2524 - val_loss: 6014824.6665 - val_acc: 0.2585\n",
      "Epoch 35/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 55472.6635 - acc: 0.2524 - val_loss: 6166923.6062 - val_acc: 0.2585\n",
      "Epoch 36/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 41494.4140 - acc: 0.2524 - val_loss: 6109964.0339 - val_acc: 0.2585\n",
      "Epoch 37/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 66294.1858 - acc: 0.2524 - val_loss: 6195318.0821 - val_acc: 0.2585\n",
      "Epoch 38/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 49962.7660 - acc: 0.2524 - val_loss: 6027933.1043 - val_acc: 0.2585\n",
      "Epoch 39/100\n",
      "4236/4236 [==============================] - 5s 1ms/step - loss: 59939.5140 - acc: 0.2524 - val_loss: 6172590.3648 - val_acc: 0.2585\n",
      "Epoch 40/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 58873.0778 - acc: 0.2524 - val_loss: 6130393.1268 - val_acc: 0.2585\n",
      "Epoch 41/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 70845.1756 - acc: 0.2524 - val_loss: 6097994.9827 - val_acc: 0.2585\n",
      "Epoch 42/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 77358.9517 - acc: 0.2524 - val_loss: 6142798.4683 - val_acc: 0.2585\n",
      "Epoch 43/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 43832.9719 - acc: 0.2524 - val_loss: 6033466.0287 - val_acc: 0.2585\n",
      "Epoch 44/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 60367.2632 - acc: 0.2524 - val_loss: 6148274.4990 - val_acc: 0.2585\n",
      "Epoch 45/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 69553.3388 - acc: 0.2524 - val_loss: 6119487.0259 - val_acc: 0.2585\n",
      "Epoch 46/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 35186.4817 - acc: 0.2524 - val_loss: 6137437.6898 - val_acc: 0.2585\n",
      "Epoch 47/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 45936.4401 - acc: 0.2524 - val_loss: 6200777.5717 - val_acc: 0.2585\n",
      "Epoch 48/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 55814.8337 - acc: 0.2524 - val_loss: 6032422.7809 - val_acc: 0.2585\n",
      "Epoch 49/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 57822.4306 - acc: 0.2524 - val_loss: 6137666.7790 - val_acc: 0.2585\n",
      "Epoch 50/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 60769.5160 - acc: 0.2524 - val_loss: 6136055.2693 - val_acc: 0.2585\n",
      "Epoch 51/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 53640.4293 - acc: 0.2524 - val_loss: 5946288.5061 - val_acc: 0.2585\n",
      "Epoch 52/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 70021.4488 - acc: 0.2524 - val_loss: 6096863.2533 - val_acc: 0.2585\n",
      "Epoch 53/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 55714.4216 - acc: 0.2524 - val_loss: 6074242.0728 - val_acc: 0.2585\n",
      "Epoch 54/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 41575.3180 - acc: 0.2524 - val_loss: 6087025.3492 - val_acc: 0.2585\n",
      "Epoch 55/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 45881.5694 - acc: 0.2524 - val_loss: 6021884.7720 - val_acc: 0.2585\n",
      "Epoch 56/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 58544.7951 - acc: 0.2524 - val_loss: 6113272.8154 - val_acc: 0.2585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 62546.7399 - acc: 0.2524 - val_loss: 6154441.7151 - val_acc: 0.2585\n",
      "Epoch 58/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 41634.0523 - acc: 0.2524 - val_loss: 6169412.3637 - val_acc: 0.2585\n",
      "Epoch 59/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 49469.7343 - acc: 0.2524 - val_loss: 6093748.8627 - val_acc: 0.2585\n",
      "Epoch 60/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 49302.9886 - acc: 0.2524 - val_loss: 6162251.4707 - val_acc: 0.2585\n",
      "Epoch 61/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 43140.5787 - acc: 0.2524 - val_loss: 6151303.0808 - val_acc: 0.2585\n",
      "Epoch 62/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 58630.8238 - acc: 0.2524 - val_loss: 6157351.8649 - val_acc: 0.2585\n",
      "Epoch 63/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 48900.5680 - acc: 0.2524 - val_loss: 6101059.7416 - val_acc: 0.2585\n",
      "Epoch 64/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 50577.2717 - acc: 0.2524 - val_loss: 6105170.4366 - val_acc: 0.2585\n",
      "Epoch 65/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 62005.1973 - acc: 0.2524 - val_loss: 6158308.3719 - val_acc: 0.2585\n",
      "Epoch 66/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 67706.4734 - acc: 0.2524 - val_loss: 6091689.6745 - val_acc: 0.2585\n",
      "Epoch 67/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 59340.7043 - acc: 0.2524 - val_loss: 6102333.1565 - val_acc: 0.2585\n",
      "Epoch 68/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 62446.8260 - acc: 0.2524 - val_loss: 6059066.1508 - val_acc: 0.2585\n",
      "Epoch 69/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 50519.1159 - acc: 0.2524 - val_loss: 6201755.6792 - val_acc: 0.2585\n",
      "Epoch 70/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 55158.3038 - acc: 0.2524 - val_loss: 6122122.1729 - val_acc: 0.2585\n",
      "Epoch 71/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 55825.5947 - acc: 0.2524 - val_loss: 6149381.3742 - val_acc: 0.2585\n",
      "Epoch 72/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 55689.3076 - acc: 0.2524 - val_loss: 5987995.1139 - val_acc: 0.2585\n",
      "Epoch 73/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 51680.2212 - acc: 0.2524 - val_loss: 6129143.5448 - val_acc: 0.2585\n",
      "Epoch 74/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 54758.6924 - acc: 0.2524 - val_loss: 6077969.1305 - val_acc: 0.2585\n",
      "Epoch 75/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 48207.1583 - acc: 0.2524 - val_loss: 6196493.7336 - val_acc: 0.2585\n",
      "Epoch 76/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 44827.9562 - acc: 0.2524 - val_loss: 6138828.4177 - val_acc: 0.2585\n",
      "Epoch 77/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 49860.7824 - acc: 0.2524 - val_loss: 6271629.3395 - val_acc: 0.2585\n",
      "Epoch 78/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 49798.7013 - acc: 0.2524 - val_loss: 6135756.4350 - val_acc: 0.2585\n",
      "Epoch 79/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 49677.1467 - acc: 0.2524 - val_loss: 6045674.4468 - val_acc: 0.2585\n",
      "Epoch 80/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 45979.3894 - acc: 0.2524 - val_loss: 6128858.6793 - val_acc: 0.2585\n",
      "Epoch 81/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 35817.9159 - acc: 0.2524 - val_loss: 6067712.8993 - val_acc: 0.2585\n",
      "Epoch 82/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 57900.4340 - acc: 0.2524 - val_loss: 6181689.4971 - val_acc: 0.2585\n",
      "Epoch 83/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 48622.9871 - acc: 0.2524 - val_loss: 6167574.4716 - val_acc: 0.2585\n",
      "Epoch 84/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 57070.2618 - acc: 0.2524 - val_loss: 6196798.7619 - val_acc: 0.2585\n",
      "Epoch 85/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 64027.7949 - acc: 0.2524 - val_loss: 6104419.6832 - val_acc: 0.2585\n",
      "Epoch 86/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 58502.5636 - acc: 0.2524 - val_loss: 6157717.4074 - val_acc: 0.2585\n",
      "Epoch 87/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 47717.8019 - acc: 0.2524 - val_loss: 6139674.2463 - val_acc: 0.2585\n",
      "Epoch 88/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 41632.0431 - acc: 0.2524 - val_loss: 6066869.1600 - val_acc: 0.2585\n",
      "Epoch 89/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 58775.6447 - acc: 0.2524 - val_loss: 6127278.7362 - val_acc: 0.2585\n",
      "Epoch 90/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 39079.5575 - acc: 0.2524 - val_loss: 6175951.8688 - val_acc: 0.2585\n",
      "Epoch 91/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 60214.0510 - acc: 0.2524 - val_loss: 6123186.1643 - val_acc: 0.2585\n",
      "Epoch 92/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 40253.8232 - acc: 0.2524 - val_loss: 6090062.1789 - val_acc: 0.2585\n",
      "Epoch 93/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 39006.9203 - acc: 0.2524 - val_loss: 6160235.7357 - val_acc: 0.2585\n",
      "Epoch 94/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 42079.0723 - acc: 0.2524 - val_loss: 6163031.6533 - val_acc: 0.2585\n",
      "Epoch 95/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 50890.1803 - acc: 0.2524 - val_loss: 6020008.1122 - val_acc: 0.2585\n",
      "Epoch 96/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 58763.5937 - acc: 0.2524 - val_loss: 6193181.7991 - val_acc: 0.2585\n",
      "Epoch 97/100\n",
      "4236/4236 [==============================] - 6s 1ms/step - loss: 47870.3693 - acc: 0.2524 - val_loss: 6042805.0632 - val_acc: 0.2585\n",
      "Epoch 98/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 45999.1911 - acc: 0.2524 - val_loss: 6168819.9431 - val_acc: 0.2585\n",
      "Epoch 99/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 34437.1177 - acc: 0.2524 - val_loss: 6087175.8124 - val_acc: 0.2585\n",
      "Epoch 100/100\n",
      "4236/4236 [==============================] - 6s 2ms/step - loss: 55728.6153 - acc: 0.2524 - val_loss: 6158782.9129 - val_acc: 0.2585\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(trainX, trainY, validation_data=(testX, testY), epochs=100, batch_size=8,\n",
    "                                 callbacks=[csv_logger]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"audio_model1.h5\")\n",
    "model_json = model.to_json()\n",
    "with open(\"audio_model1.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 6.16e+06\n",
      "Test accuracy: 0.258\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss, accuracy  = model.evaluate(testX, testY, verbose=False)\n",
    "print(f'Test loss: {loss:.3}')\n",
    "print(f'Test accuracy: {accuracy:.3}')\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5,5))\n",
    "ax.plot((history.history['acc']), 'r', label='train')\n",
    "ax.plot((history.history['val_acc']), 'b' ,label='val')\n",
    "ax.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax.set_ylabel(r'Accuracy', fontsize=20)\n",
    "ax.legend()\n",
    "ax.tick_params(labelsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(np.expand_dims(x.reshape(x.shape[0], w_rh, h_rh), axis = -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test MSE: 0.16286570165047512\n"
     ]
    }
   ],
   "source": [
    "print('Model test MSE: {}'.format(mean_squared_error(y_pred, y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred > 0.1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Not good - no hotness predicted*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
