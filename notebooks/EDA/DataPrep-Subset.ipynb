{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "span.sub-q {\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "div.gc { \n",
       "\tbackground-color: #AEDE94;\n",
       "\tborder-color: #E9967A; \t \n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 12pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import datetime\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import tables\n",
    "import io\n",
    "import gzip\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tables\n",
    "# !pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the Million Song Dataset subset (uncompressed) - change to the location on your laptop\n",
    "# Cannot store this on github as it is too large\n",
    "msd_subset_path = '../../MSD_data/MillionSongSubset/'\n",
    "\n",
    "# Keep these - folders match the structure of the uncompressed file\n",
    "msd_subset_data_path = os.path.join(msd_subset_path, 'data')\n",
    "msd_subset_addf_path = os.path.join(msd_subset_path, 'AdditionalFiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load previously saved file\n",
    "subset_full = pd.read_pickle(msd_subset_path+'subset_full.pkl')\n",
    "# keyData = pd.read_pickle(msd_subset_path+'keydata.pkl')\n",
    "# keyDataAndH = pd.read_pickle(msd_subset_path+'keydata_and_hotness.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyData = subset_full[[\"track_id\", \"song_id\", \"song_hotttnesss\"]]\n",
    "keyDataAndH = subset_full[[\"track_id\", \"song_id\", \"song_hotttnesss\"]].dropna()\n",
    "keyData.to_pickle(msd_subset_path+'keydata.pkl')\n",
    "keyDataAndH.to_pickle(msd_subset_path+'keydata_and_hotness.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure sid_mismatches.txt is gzipped before running this!\n",
    "def prepSidMismatch() :\n",
    "    with io.TextIOWrapper(gzip.open('../../MSD_data/sid_mismatches_prep.txt.gz', \"w\")) as preproc:\n",
    "        with io.TextIOWrapper(gzip.open('../../MSD_data/sid_mismatches.txt.gz', \"r\")) as src:\n",
    "            preproc.write('song_id,track_id\\n')\n",
    "            for line in src:\n",
    "                line = ','.join([w.replace('<', '').replace('>', '') for w in line.split(' ')[1:3]]) + '\\n'\n",
    "                preproc.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepSidMismatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mism_data = pd.read_csv('../../MSD_data/sid_mismatches_prep.txt.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SSD data is at https://drive.google.com/open?id=1p0_2sURyJmFIlMf0fk9SjtWc2CT7s-Gu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh_data = pd.read_csv('../../MSD_data/msd-rh.csv.gz', header=None, compression='gzip', escapechar='\\'')\n",
    "rh_data[60]=rh_data[60].str.replace(',','')\n",
    "rh_data.rename(columns={60: 'track_id'}, inplace=True)\n",
    "rh_hotness = keyDataAndH.merge(rh_data, how = 'left', on = 'track_id')\n",
    "rh_hotness.to_pickle(msd_subset_path+'rh_and_hotness.pkl')\n",
    "rh_hotness = pd.read_pickle(msd_subset_path+'rh_and_hotness.pkl')\n",
    "keys = ['track_id', 'song_id']\n",
    "idx1 = set(rh_hotness.set_index(keys).index)\n",
    "idx2 = set(mism_data.set_index(keys).index)\n",
    "df_clean=pd.DataFrame(list(idx1 - idx2), columns=keys)\n",
    "rh_hotness_clean = rh_hotness.merge(df_clean, how = 'left', on = keys)\n",
    "rh_hotness_clean.to_pickle(msd_subset_path+'rh_and_hotness_clean.pkl')\n",
    "ssd_data = pd.read_csv('../../MSD_data/msd-ssd-v1.0.csv.gz', header=None, compression='gzip', escapechar='\\'')\n",
    "ssd_data[168]=ssd_data[168].str.replace(',','')\n",
    "ssd_data.rename(columns={168: 'track_id'}, inplace=True)\n",
    "ssd_hotness = keyDataAndH.merge(ssd_data, how = 'left', on = 'track_id')\n",
    "ssd_hotness.to_pickle(msd_subset_path+'ssd_and_hotness.pkl')\n",
    "idx1 = set(ssd_hotness.set_index(keys).index)\n",
    "df_clean=pd.DataFrame(list(idx1 - idx2), columns=keys)\n",
    "ssd_hotness_clean = ssd_hotness.merge(df_clean, how = 'left', on = keys)\n",
    "ssd_hotness_clean.to_pickle(msd_subset_path+'ssd_and_hotness_clean.pkl')\n",
    "# rh_hotness_clean = pd.read_pickle(msd_subset_path+'rh_and_hotness_clean.pkl')\n",
    "# ssd_hotness_clean = pd.read_pickle(msd_subset_path+'ssd_and_hotness_clean.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5648, 171)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssd_data = pd.read_csv('../../MSD_data/msd-ssd-v1.0.csv.gz', header=None, compression='gzip', escapechar='\\'')\n",
    "ssd_data[168]=ssd_data[168].str.replace(',','')\n",
    "ssd_data.rename(columns={168: 'track_id'}, inplace=True)\n",
    "ssd_hotness = keyDataAndH.merge(ssd_data, how = 'left', on = 'track_id')\n",
    "ssd_hotness.to_pickle(msd_subset_path+'ssd_and_hotness.pkl')\n",
    "idx1 = set(ssd_hotness.set_index(keys).index)\n",
    "df_clean=pd.DataFrame(list(idx1 - idx2), columns=keys)\n",
    "ssd_hotness_clean = ssd_hotness.merge(df_clean, how = 'left', on = keys)\n",
    "ssd_hotness_clean.to_pickle(msd_subset_path+'ssd_and_hotness_clean.pkl')\n",
    "ssd_hotness_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
